[id="adopting-the-compute-service_{context}"]

//:context: adopting-compute-service
//kgilliga: This module might be converted to an assembly, or a procedure as a standalone chapter.
//Check xref contexts.

= Adopting the Compute service

*NOTE* This example scenario describes a simple single-cell setup. Real
multi-stack topology recommended for production use results in different
cells DBs layout, and should be using different naming schemes (not covered
here this time).

== Prerequisites

* Previous Adoption steps completed. Notably,
 ** the xref:migrating-databases-to-mariadb-instances_{context}[Migrating databases to MariaDB instances]
must already be imported into the podified MariaDB;
 ** the xref:adopting-the-identity-service_{context}[Adopting the Identity service] needs to be imported;
 ** the xref:adopting-the-key-manager-service_{context}[Key manager service] needs to be imported;
 ** the xref:adopting-the-placement-service_{context}[Adopting the Placement service] needs to be imported;
 ** the xref:adopting-the-image-service_{context}[Adopting the Image service] needs to be imported;
 ** the xref:migrating-ovn-data_{context}[Migrating OVN data] need to be imported;
 ** the xref:adopting-the-openstack-networking-service_{context}[Adopting the OpenStack Networking service] needs to be imported;
 ** Required services specific topology
xref:pulling-the-openstack-configuration_{context}[Pulling the OpenStack configuration].
//kgilliga: this xref should specifically point to the Get services topology specific configuration module when it's ready.
 ** OpenStack services have been stopped. For more information, see xref:stopping-openstack-services_{context}[Stopping OpenStack services].

== Variables

Define the shell variables and aliases used in the steps below. The values are
just illustrative, use values that are correct for your environment:

----
alias openstack="oc exec -t openstackclient -- openstack"
----

== Procedure - Nova adoption


*NOTE*: This procedure assumes that Nova Metadata is deployed on the top level and not on each cell level, so this example imports it the same way. If the source deployment has a per cell metadata deployment, adjust the given below patch as needed. Metadata service cannot be run in `cell0`.


* Patch OpenStackControlPlane to deploy Nova:
+
[source,yaml]
----
oc patch openstackcontrolplane openstack -n openstack --type=merge --patch '
spec:
  nova:
    enabled: true
    apiOverride:
      route: {}
    template:
      secret: osp-secret
      apiServiceTemplate:
        override:
          service:
            internal:
              metadata:
                annotations:
                  metallb.universe.tf/address-pool: internalapi
                  metallb.universe.tf/allow-shared-ip: internalapi
                  metallb.universe.tf/loadBalancerIPs: 172.17.0.80
              spec:
                type: LoadBalancer
        customServiceConfig: |
          [workarounds]
          disable_compute_service_check_for_ffu=true
      metadataServiceTemplate:
        enabled: true # deploy single nova metadata on the top level
        override:
          service:
            metadata:
              annotations:
                metallb.universe.tf/address-pool: internalapi
                metallb.universe.tf/allow-shared-ip: internalapi
                metallb.universe.tf/loadBalancerIPs: 172.17.0.80
            spec:
              type: LoadBalancer
        customServiceConfig: |
          [workarounds]
          disable_compute_service_check_for_ffu=true
      schedulerServiceTemplate:
        customServiceConfig: |
          [workarounds]
          disable_compute_service_check_for_ffu=true
      cellTemplates:
        cell0:
          conductorServiceTemplate:
            customServiceConfig: |
              [workarounds]
              disable_compute_service_check_for_ffu=true
        cell1:
          metadataServiceTemplate:
            enabled: false # enable here to run it in a cell instead
            override:
                service:
                  metadata:
                    annotations:
                      metallb.universe.tf/address-pool: internalapi
                      metallb.universe.tf/allow-shared-ip: internalapi
                      metallb.universe.tf/loadBalancerIPs: 172.17.0.80
                  spec:
                    type: LoadBalancer
            customServiceConfig: |
              [workarounds]
              disable_compute_service_check_for_ffu=true
          conductorServiceTemplate:
            customServiceConfig: |
              [workarounds]
              disable_compute_service_check_for_ffu=true
'
----

* Wait for Nova control plane services' CRs to become ready:
+
----
oc wait --for condition=Ready --timeout=300s Nova/nova
----
+
The local Conductor services will be started for each cell, while the superconductor runs in `cell0`.
Note that `disable_compute_service_check_for_ffu` is mandatory for all imported Nova services, until the external data plane is imported, and until Nova Compute services fast-forward upgraded. For more information, see xref:adopting-dataplane_{context}[Data Plane Adoption].

== Post-checks

* Check that Nova endpoints are defined and pointing to the
podified FQDNs and that Nova API responds.
+
----
openstack endpoint list | grep nova
openstack server list
----

Compare the following outputs with the topology specific configuration in xref:pulling-the-openstack-configuration_{context}[Pulling the OpenStack configuration].

* Query the superconductor for cell1 existance and compare it to pre-adoption values:
+
----
. ~/.source_cloud_exported_variables
echo $PULL_OPENSTACK_CONFIGURATION_NOVAMANAGE_CELL_MAPPINGS
oc rsh nova-cell0-conductor-0 nova-manage cell_v2 list_cells | grep -F '| cell1 |'
----
+
The expected changes to happen:

 ** cell1's `nova` DB and user name become `nova_cell1`.
 ** Default cell is renamed to `cell1` (in a multi-cell setup, it should become indexed as the last cell instead).
 ** RabbitMQ transport URL no longer uses `guest`.

*NOTE* At this point, Nova control plane services have yet taken control over
existing Nova compute workloads. That would become possible to verify only after
the data plane adoption is completed. For more information, see xref:adopting-dataplane_{context}[Data Plane Adoption].
