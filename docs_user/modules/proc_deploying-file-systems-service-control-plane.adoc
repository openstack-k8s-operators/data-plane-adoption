:_mod-docs-content-type: PROCEDURE
[id="deploying-file-systems-service-control-plane_{context}"]

= Deploying the {rhos_component_storage_file} on the control plane

[role="_abstract"]
Copy the {rhos_component_storage_file_first_ref} configuration from the {rhos_prev_long} ({OpenStackShort}) {rhos_prev_ver} deployment, and then deploy the {rhos_component_storage_file} on the control plane.

[NOTE]
====
In a {rhos_prev_long} DCN deployment, the {rhos_component_storage_file} runs only at the central site and is not deployed on edge site compute nodes. After adoption, {rhos_long} supports deploying the {rhos_component_storage_file} at edge sites if required.
====

.Prerequisites

* The {rhos_component_storage_file} systemd services such as `api`, `cron`, and `scheduler` are stopped. For more information, see xref:stopping-openstack-services_migrating-databases[Stopping {rhos_prev_long} services].
* If the deployment uses CephFS through NFS as a storage back end, the Pacemaker ordering and collocation constraints are adjusted. For more information, see xref:stopping-openstack-services_migrating-databases[Stopping {rhos_prev_long} services].
* The {rhos_component_storage_file} Pacemaker service (`openstack-manila-share`) is stopped. For more information, see xref:stopping-openstack-services_migrating-databases[Stopping {rhos_prev_long} services].
* The database migration is complete. For more information, see xref:migrating-databases-to-mariadb-instances_migrating-databases[Migrating databases to MariaDB instances].
* The {rhocp_long} nodes where the `manila-share` service is to be deployed can reach the management network that the storage system is in.
* If the deployment uses CephFS through NFS as a storage back end, a new clustered Ceph NFS service is deployed on the {CephCluster} cluster with the help
of Ceph orchestrator. For more information, see xref:creating-a-ceph-nfs-cluster_ceph-prerequisites[Creating a Ceph NFS cluster].
* Services such as the {identity_service_first_ref} and memcached are available prior to adopting the Shared File Systems services.
* If you enabled tenant-driven networking by setting `driver_handles_share_servers=True`, the {networking_first_ref} is deployed.
ifeval::["{build}" != "downstream"]
* Define the `CONTROLLER1_SSH` environment variable if it link:stop_openstack_services.md#variables[hasn't been
defined] already. Replace the following example values with values that are correct for your environment:
+
----
$ CONTROLLER1_SSH="ssh -i <path to SSH key> root@<node IP>"
----
endif::[]
ifeval::["{build}" != "upstream"]
* The `CONTROLLER1_SSH` environment variable is defined and points to the {OpenStackShort} Controller node. Replace the following example values with values that are correct for your environment:
+
----
$ CONTROLLER1_SSH="ssh -i <path to SSH key> root@<node IP>"
----
endif::[]

.Procedure

. Copy the configuration file from {OpenStackShort} {rhos_prev_ver} for reference:
+
----
$ CONTROLLER1_SSH cat /var/lib/config-data/puppet-generated/manila/etc/manila/manila.conf | awk '!/^ *#/ && NF' > ~/manila.conf
----

. Review the configuration file for configuration changes that were made since {OpenStackShort} {rhos_prev_ver}. For more information on preparing this file for {rhos_long}, see xref:preparing-the-shared-file-systems-service-configuration_adopting-shared-file-systems[Guidelines for preparing the {rhos_component_storage_file} configuration].
// - TODO link config diff tables for RHOSP 17.1 (Wallaby) to RHOSP 18 (Antelope) -

. Create a patch file for the `OpenStackControlPlane` CR to deploy the {rhos_component_storage_file}. The following example `manila.patch` file uses native CephFS:
+
----
$ cat << __EOF__ > ~/manila.patch
spec:
  manila:
    enabled: true
    apiOverride:
      route: {}
    template:
      databaseInstance: openstack
      databaseAccount: manila
      secret: osp-secret
      manilaAPI:
        replicas: 3
        customServiceConfig: |
          [DEFAULT]
          enabled_share_protocols = cephfs
        override:
          service:
            internal:
              metadata:
                annotations:
                  metallb.universe.tf/address-pool: internalapi
                  metallb.universe.tf/allow-shared-ip: internalapi
                  metallb.universe.tf/loadBalancerIPs: <172.17.0.80>
              spec:
                type: LoadBalancer
      manilaScheduler:
        replicas: 3
      manilaShares:
        cephfs:
          replicas: 1
          customServiceConfig: |
            [DEFAULT]
            enabled_share_backends = tripleo_ceph
            host = hostgroup
            [cephfs]
            driver_handles_share_servers=False
            share_backend_name=cephfs
            share_driver=manila.share.drivers.cephfs.driver.CephFSDriver
            cephfs_conf_path=/etc/ceph/ceph.conf
            cephfs_auth_id=openstack
            cephfs_cluster_name=ceph
            cephfs_volume_mode=0755
            cephfs_protocol_helper_type=CEPHFS
          networkAttachments:
              - storage
      extraMounts:
      - name: v1
        region: r1
        extraVol:
          - propagation:
            - ManilaShare
          extraVolType: Ceph
          volumes:
          - name: ceph
            secret:
              secretName: ceph-conf-files
          mounts:
          - name: ceph
            mountPath: "/etc/ceph"
            readOnly: true
__EOF__
----
+
* `metallb.universe.tf/loadBalancerIPs:<172.17.0.80>` specifies the load balancer IP in your environment. If you use IPv6, change the load balancer IP to the load balancer IP in your environment, for example, `metallb.universe.tf/loadBalancerIPs: fd00:bbbb::80`.
* `share_backend_name` specifies the names of the back ends to use in {rhos_long}. Ensure that the names of the back ends are the same as they were in {OpenStackShort} {rhos_prev_ver}.
* `networkAttachments` specifies the appropriate storage management network. For example, the `manilaShares` instance with the CephFS back-end driver is connected to the `storage` network.
* `extraMounts` specifies additional files to add to any of the services. For example, when using {Ceph}, you can add the {rhos_component_storage_file} Ceph user's keyring file as well as the `ceph.conf` configuration file.
* In a DCN deployment where {Ceph} configuration files are named by cluster (for example, `central.conf` instead of `ceph.conf`), set `cephfs_conf_path` to the path of the configuration file for the cluster hosting the CephFS back end, and set `cephfs_cluster_name` to the corresponding cluster name. For example, `cephfs_conf_path=/etc/ceph/central.conf` and `cephfs_cluster_name=central`. Using `/etc/ceph/ceph.conf` when that file does not exist in the mounted secret will cause the `manila-share` service to fail with a `conf_read_file` error.
+
The following example patch file uses CephFS through NFS:
+
----
$ cat << __EOF__ > ~/manila.patch
spec:
  manila:
    enabled: true
    apiOverride:
      route: {}
    template:
      databaseInstance: openstack
      secret: osp-secret
      manilaAPI:
        replicas: 3
        customServiceConfig: |
          [DEFAULT]
          enabled_share_protocols = cephfs
        override:
          service:
            internal:
              metadata:
                annotations:
                  metallb.universe.tf/address-pool: internalapi
                  metallb.universe.tf/allow-shared-ip: internalapi
                  metallb.universe.tf/loadBalancerIPs: <172.17.0.80>
              spec:
                type: LoadBalancer
      manilaScheduler:
        replicas: 3
      manilaShares:
        cephfs:
          replicas: 1
          customServiceConfig: |
            [DEFAULT]
            enabled_share_backends = cephfs
            host = hostgroup
            [cephfs]
            driver_handles_share_servers=False
            share_backend_name=tripleo_ceph
            share_driver=manila.share.drivers.cephfs.driver.CephFSDriver
            cephfs_conf_path=/etc/ceph/ceph.conf
            cephfs_auth_id=openstack
            cephfs_cluster_name=ceph
            cephfs_protocol_helper_type=NFS
            cephfs_nfs_cluster_id=cephfs
            cephfs_ganesha_server_ip=172.17.5.47
          networkAttachments:
              - storage
__EOF__
----
+
* Prior to adopting the `manilaShares` service for CephFS through NFS, ensure that you create a clustered Ceph NFS service. The name of the service must be `cephfs_nfs_cluster_id`. The `cephfs_nfs_cluster_id` option is set with the name of the NFS cluster created on {Ceph}.
* The `cephfs_ganesha_server_ip` option is preserved from the configuration on the {OpenStackShort} {rhos_prev_ver} environment.

. Patch the `OpenStackControlPlane` CR:
+
----
$ oc patch openstackcontrolplane openstack --type=merge --patch-file=~/<manila.patch>
----
+
* Replace `<manila.patch>` with the name of your patch file.

.Verification

. Inspect the resulting {rhos_component_storage_file} pods:
+
----
$ oc get pods -l service=manila
----

. Check that the Shared File Systems API service is registered in the {identity_service_first_ref}:
+
----
$ openstack service list | grep manila
----
+
----
$ openstack endpoint list | grep manila

| 1164c70045d34b959e889846f9959c0e | regionOne | manila       | share        | True    | internal  | http://manila-internal.openstack.svc:8786/v1/%(project_id)s        |
| 63e89296522d4b28a9af56586641590c | regionOne | manilav2     | sharev2      | True    | public    | https://manila-public-openstack.apps-crc.testing/v2                |
| af36c57adcdf4d50b10f484b616764cc | regionOne | manila       | share        | True    | public    | https://manila-public-openstack.apps-crc.testing/v1/%(project_id)s |
| d655b4390d7544a29ce4ea356cc2b547 | regionOne | manilav2     | sharev2      | True    | internal  | http://manila-internal.openstack.svc:8786/v2                       |
----

. Test the health of the service:
+
----
$ openstack share service list
$ openstack share pool list --detail
----

. Check existing workloads:
+
----
$ openstack share list
$ openstack share snapshot list
----
ifeval::["{build}" != "downstream"]
. You can create further resources:
+
----
$ openstack share create cephfs 10 --snapshot mysharesnap --name myshareclone
$ openstack share create nfs 10 --name mynfsshare
$ openstack share export location list mynfsshare
----
endif::[]
