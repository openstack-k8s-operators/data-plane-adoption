[id="ospdo_scale_down_pre_database_adoption_{context}"]

= Scaling down director Operator resources

Before you migrate your databases to the control plane, you must scale down and remove director Operator (OSPdO) resources in order to use the {rhos_long} resources.

.Procedure

. Scale down the {rhos_acro} OpenStack Operator `controller-manager` to 0 replicas and temporarily delete the `OpenStackControlPlane` `OpenStackClient` pod, so that you can use the OSPdO `controller-manager` to clean up some of its resources. The cleanup is needed to avoid a pod name collision between the OSPdO OpenStackClient and the {rhos_acro} OpenStackClient.
+
----
$ oc patch csv -n openstack-operators openstack-operator.v0.0.1 --type json   -p="[{"op": "replace", "path": "/spec/install/spec/deployments/0/spec/replicas", "value": "0"}]"
$ oc delete openstackclients.client.openstack.org --all
----
+
. Delete the OSPdO `OpenStackControlPlane` custom resource (CR):
+
----
$ oc delete openstackcontrolplanes.osp-director.openstack.org -n openstack --all
----
. Delete the OSPdO `OpenStackNetConfig` CR to remove the associated node network configuration policies:
+
----
$ oc delete osnetconfig -n openstack --all
----
. Label the {OpenShiftShort} node that contains the OSPdO virtual machine (VM):
+
----
$ oc label nodes <ospdo_vm_master_node> type=openstack
----
+
* Replace ` <ospdo_vm_master_node>` with the remaining master node that contains the OSPdO VM.
. Create a node network configuration policy for the third {OpenShiftShort} node. For example:
+
----
$ cat << EOF > /tmp/node3_nncp.yaml
apiVersion: nmstate.io/v1
kind: NodeNetworkConfigurationPolicy
metadata:
  labels:
    osp/interface: enp7s0
  name: <ostest-master-node>
spec:
  desiredState:
    dns-resolver:
      config:
        search: []
        server:
        - 172.22.0.1
    interfaces:
    - description: internalapi vlan interface
      name: enp7s0.20
      state: up
      type: vlan
      vlan:
        base-iface: enp7s0
        id: 20
        reorder-headers: true
      ipv4:
        address:
        - ip: 172.17.0.7
          prefix-length: 24
        enabled: true
        dhcp: false
      ipv6:
        enabled: false
    - description: storage vlan interface
      name: enp7s0.30
      state: up
      type: vlan
      vlan:
        base-iface: enp7s0
        id: 30
        reorder-headers: true
      ipv4:
        address:
        - ip: 172.18.0.7
          prefix-length: 24
        enabled: true
        dhcp: false
      ipv6:
        enabled: false
    - description: storagemgmt vlan interface
      name: enp7s0.40
      state: up
      type: vlan
      vlan:
        base-iface: enp7s0
        id: 40
        reorder-headers: true
      ipv4:
        address:
        - ip: 172.19.0.7
          prefix-length: 24
        enabled: true
        dhcp: false
      ipv6:
        enabled: false
    - description: tenant vlan interface
      name: enp7s0.50
      state: up
      type: vlan
      vlan:
        base-iface: enp7s0
        id: 50
        reorder-headers: true
      ipv4:
        address:
        - ip: 172.20.0.7
          prefix-length: 24
        enabled: true
        dhcp: false
      ipv6:
        enabled: false
    - description: Configuring Bridge br-ctlplane with interface enp7s0
      name: br-ctlplane
      mtu: 1500
      type: linux-bridge
      state: up
      bridge:
        options:
          stp:
            enabled: false
        port:
          - name: enp1s0
            vlan: {}
      ipv4:
        address:
        - ip: 172.22.0.53
          prefix-length: 24
        enabled: true
        dhcp: false
      ipv6:
        enabled: false
    - bridge:
        options:
          stp:
            enabled: false
        port:
        - name: enp6s0
      description: Linux bridge with enp6s0 as a port
      ipv4:
        enabled: false
      ipv6:
        enabled: false
      mtu: 1500
      name: br-external
      state: up
      type: linux-bridge
  nodeSelector:
    kubernetes.io/hostname: <ostest-master-node>
    node-role.kubernetes.io/worker: ""
EOF

$ oc apply -f /tmp/node3_nncp.yaml
----
. Get the remaining OSPdO resources and delete everything. Do not delete the `OpenStackBaremetalSets` and `OpenStackProvisionServer` resources:
+
----
$ for i in $(oc get crd | grep osp-director | grep -v baremetalset | grep -v provisionserver | awk {'print $1'}); do echo Deleting $i...; oc delete $i -n openstack --all; done
----
. Scale down OSPdO to 0 replicas:
+
----
$ ospdo_csv_ver=$(oc get csv -n openstack -l operators.coreos.com/osp-director-operator.openstack -o json | jq -r '.items[0].metadata.name')
$ oc patch csv -n openstack $ospdo_csv_ver --type json   -p="[{"op": "replace", "path": "/spec/install/spec/deployments/0/spec/replicas", "value": "0"}]"
----
. Remove the webhooks from OSPdO:
+
----
$ oc patch csv $ospdo_csv_ver -n openstack --type json -p="[{"op": "remove", "path": "/spec/webhookdefinitions"}]"
----
. Remove the finalizer from the OSPdO `OpenStackBaremetalSet` resource:
+
----
$ oc patch openstackbaremetalsets.osp-director.openstack.org -n openstack compute --type json -p="[{"op": "remove", "path": "/metadata/finalizers"}]"
----
. Delete the `OpenStackBaremetalSet` and `OpenStackProvisionServer` resources:
+
----
$ oc delete openstackbaremetalsets.osp-director.openstack.org -n openstack --all
$ oc delete openstackprovisionservers.osp-director.openstack.org -n openstack --all
----
. Annotate each {OpenStackShort} Compute `BareMetalHost` resource so that Metal3 does not start the node:
+
----
$ compute_bmh_list=$(oc get bmh -n openshift-machine-api |grep compute|awk '{printf $1 " "}')
$ for bmh_compute in $compute_bmh_list;do oc annotate bmh -n openshift-machine-api $bmh_compute baremetalhost.metal3.io/detached="";done
$ oc delete bmh -n openshift-machine-api $bmh_compute;done
----
. Delete the OSPdO Operator Lifecycle Manager resources to remove OpenStack director Operator:
+
----
$ oc delete subscription osp-director-operator -n openstack
$ oc delete operatorgroup osp-director-operator -n openstack
$ oc delete catalogsource osp-director-operator-index -n openstack
$ oc delete csv $ospdo_csv_ver -n openstack
----

. Scale up the {rhos_acro} OpenStack Operator `controller-manager` to 1 replica so that the associated `OpenStackControlPlane` CR is reconciled and its `OpenStackClient` pod is recreated:
+
----
$ oc patch csv -n openstack-operators openstack-operator.v0.0.1 --type json   -p="[{"op": "replace", "path": "/spec/install/spec/deployments/0/spec/replicas", "value": "1"}]"
----
