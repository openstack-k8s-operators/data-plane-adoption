[id="pulling-the-openstack-configuration_{context}"]

//kgilliga: This module will be converted to a procedure and likely nested under the planning assembly.

= Pulling the OpenStack configuration

Before starting the adoption workflow, pull the configuration from the OpenStack services and TripleO on your file system to back up the configuration files. You can then use the files later, during the configuration of the adopted services, and for the record to compare and make sure nothing has been missed or misconfigured.

Make sure you have pull the os-diff repository and configure according to your environment:
link:planning.md#Configuration tooling[Configure os-diff]

== Pull configuration from a TripleO deployment

Before starting you need to update your ssh parameters according to your environment in the os-diff.cfg.
Os-diff will use those parameters to connect to your Director node, query and download the configuration files:

----
ssh_cmd=ssh -F ssh.config standalone
container_engine=podman
connection=ssh
remote_config_path=/tmp/tripleo
----

Make sure the ssh command you provide in `ssh_cmd` parameter is correct and with key authentication.

Once it's done, you can start to pull configuration from your OpenStack servies.

All the services are describes in a yaml file:

https://github.com/openstack-k8s-operators/os-diff/blob/main/config.yaml[service config parameters]

You can enable or disable the services you want then you can start to pull the configuration on your local file system.
Example with default keystone:

[source,yaml]
----
# service name and file location
services:
  # Service name
  keystone:
    # Bool to enable/disable a service (not implemented yet)
    enable: true
    # Pod name, in both OCP and podman context.
    # It could be strict match or will only just grep the podman_name
    # and work with all the pods which matched with pod_name.
    # To enable/disable use strict_pod_name_match: true/false
    podman_name: keystone
    pod_name: keystone
    container_name: keystone-api
    # pod options
    # strict match for getting pod id in TripleO and podman context
    strict_pod_name_match: false
    # Path of the config files you want to analyze.
    # It could be whatever path you want:
    # /etc/<service_name> or /etc or /usr/share/<something> or even /
    # @TODO: need to implement loop over path to support multiple paths such as:
    # - /etc
    # - /usr/share
    path:
      - /etc/
      - /etc/keystone
      - /etc/keystone/keystone.conf
      - /etc/keystone/logging.conf
----

Duplicate the keystone example to each OpenStack services you want.

Then, you can pull the configuration with this command:

----
pushd os-diff
./os-diff pull
----

The configuration will be pulled and stored by default:

----
/tmp/tripleo/
----

Once it's done, you should have into your local path a directory per services such as:

----
  ▾ tmp/
    ▾ tripleo/
      ▾ glance/
      ▾ keystone/
----

== Get services topology specific configuration

Define the shell variables used in the steps below. The values are
just illustrative, use values that are correct for your environment:

----
CONTROLLER_SSH="ssh -F ~/director_standalone/vagrant_ssh_config vagrant@standalone"
ifeval::["{build}" != "downstream"]
MARIADB_IMAGE=quay.io/podified-antelope-centos9/openstack-mariadb:current-podified
endif::[]
ifeval::["{build}" == "downstream"]
MARIADB_IMAGE=registry.redhat.io/rhosp-dev-preview/openstack-mariadb-rhel9:18.0
endif::[]
SOURCE_MARIADB_IP=192.168.122.100
SOURCE_DB_ROOT_PASSWORD=$(cat ~/tripleo-standalone-passwords.yaml | grep ' MysqlRootPassword:' | awk -F ': ' '{ print $2; }')
----

Export shell variables for the following outputs to compare it with post-adoption values later on:

* Test connection to the original DB:
+
----
export PULL_OPENSTACK_CONFIGURATION_DATABASES=$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysql -rsh "$SOURCE_MARIADB_IP" -uroot -p"$SOURCE_DB_ROOT_PASSWORD" -e 'SHOW databases;')
echo "$PULL_OPENSTACK_CONFIGURATION_DATABASES"
----
+
Note the `nova`, `nova_api`, `nova_cell0` databases residing in the same DB host.

* Run mysqlcheck on the original DB to look for things that are not OK:
+
----
export PULL_OPENSTACK_CONFIGURATION_MYSQLCHECK_NOK=$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysqlcheck --all-databases -h $SOURCE_MARIADB_IP -u root -p"$SOURCE_DB_ROOT_PASSWORD" | grep -v OK)
echo "$PULL_OPENSTACK_CONFIGURATION_MYSQLCHECK_NOK"
----

* Get Nova cells mappings from database:
+
----
export PULL_OPENSTACK_CONFIGURATION_NOVADB_MAPPED_CELLS=$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysql -rsh "${SOURCE_MARIADB_IP}" -uroot -p"${SOURCE_DB_ROOT_PASSWORD}" nova_api -e \
    'select uuid,name,transport_url,database_connection,disabled from cell_mappings;')
echo "$PULL_OPENSTACK_CONFIGURATION_NOVADB_MAPPED_CELLS"
----

* Get the host names of the registered Nova compute services:
+
----

export PULL_OPENSTACK_CONFIGURATION_NOVA_COMPUTE_HOSTNAMES=$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysql -rsh "$SOURCE_MARIADB_IP" -uroot -p"$SOURCE_DB_ROOT_PASSWORD" nova_api -e \
    "select host from nova.services where services.binary='nova-compute';")
echo "$PULL_OPENSTACK_CONFIGURATION_NOVA_COMPUTE_HOSTNAMES"
----

* Get the list of mapped Nova cells:
+
----
export PULL_OPENSTACK_CONFIGURATION_NOVAMANAGE_CELL_MAPPINGS=$($CONTROLLER_SSH sudo podman exec -it nova_api nova-manage cell_v2 list_cells)
echo "$PULL_OPENSTACK_CONFIGURATION_NOVAMANAGE_CELL_MAPPINGS"
----

After the source control plane services shutdown, if either of the exported
values lost, it could be no longer evaluated again. Preserving the exported
values in an env file should protect you from such a situation:

* Store exported variables for future use
+
----
cat > ~/.source_cloud_exported_variables << EOF
PULL_OPENSTACK_CONFIGURATION_DATABASES="$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysql -rsh $SOURCE_MARIADB_IP -uroot -p$SOURCE_DB_ROOT_PASSWORD -e 'SHOW databases;')"
PULL_OPENSTACK_CONFIGURATION_MYSQLCHECK_NOK="$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysqlcheck --all-databases -h $SOURCE_MARIADB_IP -u root -p$SOURCE_DB_ROOT_PASSWORD | grep -v OK)"
PULL_OPENSTACK_CONFIGURATION_NOVADB_MAPPED_CELLS="$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysql -rsh $SOURCE_MARIADB_IP -uroot -p$SOURCE_DB_ROOT_PASSWORD nova_api -e \
    'select uuid,name,transport_url,database_connection,disabled from cell_mappings;')"
PULL_OPENSTACK_CONFIGURATION_NOVA_COMPUTE_HOSTNAMES="$(oc run mariadb-client -q --image ${MARIADB_IMAGE} -i --rm --restart=Never -- \
    mysql -rsh $SOURCE_MARIADB_IP -uroot -p$SOURCE_DB_ROOT_PASSWORD nova_api -e \
    "select host from nova.services where services.binary='nova-compute';")"
PULL_OPENSTACK_CONFIGURATION_NOVAMANAGE_CELL_MAPPINGS="$($CONTROLLER_SSH sudo podman exec -it nova_api nova-manage cell_v2 list_cells)"
EOF
chmod 0600 ~/.source_cloud_exported_variables
----

* Optionally, if there are neutron-sriov-nic-agent agents running in the deployment, get its configuration:
+
----
podman run -i --rm --userns=keep-id -u $UID $MARIADB_IMAGE mysql \
    -rsh "$SOURCE_MARIADB_IP" -uroot -p"$SOURCE_DB_ROOT_PASSWORD" ovs_neutron -e \
    "select host, configurations from agents where agents.binary='neutron-sriov-nic-agent';"
----

This configuration will be required later, during the xref:adopting-dataplane_{context}[Data Plane Adoption].
