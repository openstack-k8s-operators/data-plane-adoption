---
- name: set Neutron services shell vars
  no_log: "{{ use_no_log }}"
  ansible.builtin.set_fact:
    neutron_header: |
      alias openstack="oc exec -t openstackclient -- openstack"
      FIP={{ lookup('env', 'FIP') | default('192.168.122.20', True) }}

- name: verify that neutron-ovn-metadata-agent is alive
  ansible.builtin.shell: |
    {{ shell_header }}
    {{ neutron_header }}
    ${BASH_ALIASES[openstack]} network agent list | grep -F 'neutron-ovn-metadata-agent' | grep -qF 'XXX' || echo PASS
  register: neutron_verify_metadata_agent_result
  until: neutron_verify_metadata_agent_result.stdout == 'PASS'
  # NOTE(slaweq): retries should not be needed but it seems there is some minor
  # bug in Neutron which causes reporting ovn-metadata-agent as DOWN in every first API request after deploying it on host.
  retries: 2
  delay: 1

- name: get neutron-sriov-nic-agent alive state
  when: compute_adoption|bool
  ansible.builtin.shell: |
    {{ shell_header }}
    {{ neutron_header }}
    ${BASH_ALIASES[openstack]} network agent list | grep -F 'neutron-sriov-nic-agent' | grep -qF 'XXX' || echo ALIVE
  register: neutron_verify_sriov_nic_agent_result

- name: verify that neutron-sriov-nic-agent is alive
  when: compute_adoption|bool
  ansible.builtin.assert:
    that:
      - neutron_verify_sriov_nic_agent_result.stdout == 'ALIVE'
    fail_msg: "neutron-sriov-nic-agent is DEAD after adoption"
    success_msg: "neutron-sriov-nic-agent is ALIVE after adoption"

- name: get neutron-dhcp-agent alive state
  ansible.builtin.shell: |
    {{ shell_header }}
    {{ neutron_header }}
    ${BASH_ALIASES[openstack]} network agent list | grep -F 'neutron-dhcp-agent' | grep -qF 'XXX' || echo ALIVE
  register: neutron_verify_dhcp_agent_result

- name: verify that neutron-dhcp-agent is alive
  ansible.builtin.assert:
    that:
      - neutron_verify_dhcp_agent_result.stdout == 'ALIVE'
    fail_msg: "neutron-dhcp-agent is DEAD after adoption"
    success_msg: "neutron-dhcp-agent is ALIVE after adoption"

- name: verify connectivity to the existing test VM instance using Floating IP
  when: prelaunch_test_instance|bool
  ansible.builtin.shell: |
      ping -c4 {{ lookup('env', 'FIP') | default('192.168.122.20', True) }}

- name: stop pinger
  when: neutron_qe_test|bool
  environment:
    OS_CLOUD_IP: "{{ standalone_ip | default(edpm_node_ip) }}"
  ansible.builtin.shell: |
      ssh ${OS_CLOUD_IP} "echo 'exit' > ~/adoption/_pinger_cmd.txt </dev/null"

- name: get validation pinger logs
  when: neutron_qe_test|bool
  environment:
    OS_CLOUD_IP: "{{ standalone_ip | default(edpm_node_ip) }}"
  ansible.builtin.shell: |
      ssh ${OS_CLOUD_IP} "set -o pipefail && chmod 744 {{ neutron_qe_dir }}/validate_pinger.sh && \
      {{ neutron_qe_dir }}/validate_pinger.sh > {{ neutron_qe_dir }}/validate_pinger.sh.log 2>&1"

- name: get validation pinger result
  when: neutron_qe_test|bool
  environment:
    OS_CLOUD_IP: "{{ standalone_ip | default(edpm_node_ip) }}"
  ansible.builtin.shell: |
      ssh ${OS_CLOUD_IP} "set -o pipefail && grep -r 'res=1' {{ neutron_qe_dir }}/validate_pinger.sh.log"
  register: validation_pinger_result
  ignore_errors: true

- name: verify pinger result
  when: neutron_qe_test|bool
  ansible.builtin.assert:
    that:
      - validation_pinger_result.rc == 1
    fail_msg: "fail ping"
    success_msg: "success ping"
